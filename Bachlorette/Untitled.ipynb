{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8513f800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Q-table:\n",
      "[[-0.95542428 -1.38586318 -0.86936215 -0.94788355]\n",
      " [-0.6751121  -0.65436142 -0.69335356 -0.61823391]\n",
      " [-0.4909078  -0.3531268  -0.34416245  0.5066819 ]\n",
      " [-0.019      -0.19       -0.109       4.68559   ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-1.34951102 -1.51129082 -1.40798317 -1.43160662]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-1.64911407 -1.69984497 -1.6119771  -1.8379896 ]\n",
      " [-1.77040595 -1.82960025 -1.76027012 -1.80767124]\n",
      " [-1.73334001 -1.7647024  -1.69874994 -1.77914134]\n",
      " [-1.79749391 -1.69619813 -1.70534752 -1.62155421]\n",
      " [-6.5132156  -1.46328817 -1.53463495 -1.48470414]\n",
      " [-1.92384877 -1.95279758 -2.01504259 -2.03883711]\n",
      " [-1.9164728  -1.72089043 -1.82210779 -1.83766174]\n",
      " [-1.79626432 -1.78462878 -1.76779533 -1.72538331]\n",
      " [-1.65056572 -1.73074879 -1.70072668 -1.6776037 ]\n",
      " [-1.61438522 -1.54839672 -1.59320275 -1.60125941]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define maze environment\n",
    "GRID_HEIGHT = 4\n",
    "GRID_WIDTH = 5\n",
    "START = (3, 0)\n",
    "FLAG = (0, 4)\n",
    "FIRE = (1, 4)\n",
    "WALLS = [(1, 1), (1, 2), (1, 3)]\n",
    "\n",
    "# Define Q-learning parameters\n",
    "LEARNING_RATE = 0.1\n",
    "DISCOUNT_FACTOR = 0.9\n",
    "EXPLORATION_PROB = 1.0\n",
    "EXPLORATION_DECAY = 0.001\n",
    "EPISODES = 1000\n",
    "\n",
    "# Initialize Q-table\n",
    "q_table = np.zeros((GRID_HEIGHT * GRID_WIDTH, 4))\n",
    "\n",
    "# Helper functions\n",
    "def get_state_index(row, col):\n",
    "    return row * GRID_WIDTH + col\n",
    "\n",
    "def get_coords_from_index(index):\n",
    "    return index // GRID_WIDTH, index % GRID_WIDTH\n",
    "\n",
    "def is_valid_state(row, col):\n",
    "    return 0 <= row < GRID_HEIGHT and 0 <= col < GRID_WIDTH and (row, col) not in WALLS\n",
    "\n",
    "def get_reward(row, col):\n",
    "    if (row, col) == FLAG:\n",
    "        return 10\n",
    "    elif (row, col) == FIRE:\n",
    "        return -10\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "# Q-learning algorithm\n",
    "state = START\n",
    "for episode in range(EPISODES):\n",
    "    # Choose action\n",
    "    if np.random.uniform(0, 1) < EXPLORATION_PROB:\n",
    "        action = np.random.randint(0, 4)  # 0: up, 1: down, 2: left, 3: right\n",
    "    else:\n",
    "        state_index = get_state_index(*state)\n",
    "        action = np.argmax(q_table[state_index])\n",
    "\n",
    "    # Take action and observe reward\n",
    "    row, col = state\n",
    "    if action == 0 and is_valid_state(row - 1, col):\n",
    "        new_state = (row - 1, col)\n",
    "    elif action == 1 and is_valid_state(row + 1, col):\n",
    "        new_state = (row + 1, col)\n",
    "    elif action == 2 and is_valid_state(row, col - 1):\n",
    "        new_state = (row, col - 1)\n",
    "    elif action == 3 and is_valid_state(row, col + 1):\n",
    "        new_state = (row, col + 1)\n",
    "    else:\n",
    "        new_state = state  # Stay in the same state if action is invalid\n",
    "    reward = get_reward(*new_state)\n",
    "\n",
    "    # Update Q-value\n",
    "    state_index = get_state_index(*state)\n",
    "    new_state_index = get_state_index(*new_state)\n",
    "    q_table[state_index][action] = q_table[state_index][action] + LEARNING_RATE * (reward + DISCOUNT_FACTOR * np.max(q_table[new_state_index]) - q_table[state_index][action])\n",
    "\n",
    "    # Update state and exploration probability\n",
    "    state = new_state\n",
    "    EXPLORATION_PROB *= (1 - EXPLORATION_DECAY)\n",
    "\n",
    "    # Check if game is over\n",
    "    if state == FLAG or state == FIRE:\n",
    "        state = START  # Reset to start for the next episode\n",
    "\n",
    "# Print the final Q-table\n",
    "print(\"Final Q-table:\")\n",
    "print(q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a43ded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
